# IFT-6390-KaggleProject2

Team: SuperAkelius <br>
Abhay Puri (20209505) <br>
Saurabh Bodhe (20208545) <br>

This code repo was build as a part of the kaggle competition 2 CropHarvest - crop vs. non-crop (Crop land detection from remote sensing data) IFT 6390 Machine Learning course. The goal of this project is to implement and train several classification algorithms. In this paper, we present a comparative study of different machine learning supervised classification techniques Logistic Regression, Random Forests, XGBoost, Extra Tress and Light Gradient Boosting (LGBM). 

Best Model Public Score = 0.99757 Private Score = 0.99779 (6/50)

The code Kaggle2_Solution.ipynb requires numpy, pandas, matplotlib, seaborn, sklearn, optuna, catboost and many more libraries to run which are present in the Jupyter Notebook beforehand. 

The train data(train.csv) and test data(test.csv) must be uploaded in the Google drive because I used Google Colaboratory for the entire project. You can download it from here [Kaggle](https://www.kaggle.com/c/cropharvest-crop-detection/data?select=train.csv)
After this you can run this Jupyter notebook.

A submission.csv of extra trees classifier file would be generated that can be uploaded to the Kaggle Competition.




